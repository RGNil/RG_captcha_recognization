{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本文件用于识别老师给的几个验证码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/rgmax/Desktop/Ex2_验证码识别/image_splited'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from cv2 import cv2 as cv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "TRAIN_DATA = os.path.join(ROOT_DIR, 'digits_data')\n",
    "# TEST_DATA_CAP = os.path.join(ROOT_DIR, 'captcha_test_data')\n",
    "TEST_DATA_CHAR = os.path.join(ROOT_DIR, 'image_splited')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的一个cell的代码是分割captha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了方便图片直接显示在jupyter中，cv的imshow不能直接在jupyter中显示\n",
    "# 为了用matplotlib显示（ 不能用plt.show()，要用plt.imshow() ）\n",
    "# 由于CV的通道是BGR顺序，而matpotlib是 RGB顺序，这里要做通道转换\n",
    "# 方法一\n",
    "def bgr2rgb_v2(img):\n",
    "    # 用cv自带的分割和合并函数\n",
    "    B,G,R = cv.split(img)\n",
    "    return cv.merge([R,G,B])\n",
    "# 方法二\n",
    "def bgr2rgb(img):\n",
    "    # 直接用python切片特性，[start: end: step], 这里start end为空，则默认遍历全部，step为-1则倒序遍历\n",
    "    return img[:, :, ::-1]\n",
    "\n",
    "def genNeedImg(img_path, img_type='binary', binary_therhold=127, \n",
    "               binary_reverse=False, size=None, save=False, path='./'):\n",
    "    '''\n",
    "    用于生成指定大小的灰度图或二值图, img_path为图像路径\n",
    "    type为标志转换类型，默认为binary，可选的值为binary或gray\n",
    "    binary_therhold为二值图划分阈值，默认127（即大于127的像素设置为255，否则置0）\n",
    "    binary_reverse默认为False，True时黑白颠倒（即大于127的像素设置为0，否则置255）\n",
    "    size为tuple类型，用于指定生成图像的尺寸, 如：(512,512)，默认为None表示输出原图像尺寸\n",
    "    save为保存标志，默认为False，为true时将生成的图保存到path(默认为当前文件夹)\n",
    "    '''\n",
    "    img_raw = cv.imread(img_path)\n",
    "    if size != None: # 调整图像尺寸\n",
    "        img_raw= cv.resize(img_raw,size)\n",
    "    img_gray = cv.cvtColor(img_raw,cv.COLOR_RGB2GRAY) # 转换颜色空间为灰度\n",
    "    # Add some extra padding around the image\n",
    "    # img_gray = cv.copyMakeBorder(img_gray, 8, 8, 8, 8, cv.BORDER_REPLICATE)\n",
    "    img_name = img_path[9:].split('.')[0] # 获取图像原始名称\n",
    "    if img_type == 'gray': # 生成灰度图\n",
    "        if save:\n",
    "            cv.imwrite(os.path.join(path,'{}_gray.bmp'.format(img_name)),img_gray)\n",
    "            print('Gray image saved at {}'.format(os.path.join(path,'{}_gray.bmp'.format(img_name))))\n",
    "        else:\n",
    "            print('Gray image generated!')\n",
    "            return img_gray\n",
    "    else: # 生成二值图\n",
    "        if binary_reverse:\n",
    "            ret, img_binary = cv.threshold(img_gray,binary_therhold,255,cv.THRESH_BINARY_INV) #反二进制阈值化\n",
    "        else:\n",
    "            ret, img_binary = cv.threshold(img_gray,binary_therhold,255,cv.THRESH_BINARY)# 二进制阈值化\n",
    "        if save:\n",
    "            cv.imwrite(os.path.join(path,'{}_binary.bmp'.format(img_name)),img_binary)\n",
    "            print('threshold:{}'.format(ret)) # 输出转换阈值\n",
    "            print('Binary image savd at {}'.format(os.path.join(path,'{}_binary.bmp'.format(img_name))))\n",
    "        else:\n",
    "            print('Binary image generated!')\n",
    "            print('threshold:{}'.format(ret)) # 输出转换阈值\n",
    "            return img_binary\n",
    "\n",
    "def captcha_character_detach(captcha_img_path, save_flag=False, characters_save_path='./', captcha_len=4):\n",
    "    '''\n",
    "    这个函数是用于获取训练集时用来分割captcha的，所以会记录验证码名字\n",
    "    传入的验证码必须带有标签，验证码命名就是标签名，如 1415.png\n",
    "    '''\n",
    "    captcha_img_basename = os.path.basename(captcha_img_path) # 从路径中提取带后缀文件名，如 '0415.png'\n",
    "    captcha_text = os.path.splitext(captcha_img_basename)[0] # ['0415', 'png']\n",
    "    img_gray = cv.imread(captcha_img_path, cv.IMREAD_GRAYSCALE) # 灰度图读入\n",
    "    img_binary = genNeedImg(captcha_img_path, img_type='binary', binary_therhold=127, binary_reverse=True) # 直接调用genNeedImg生成二值图\n",
    "    contours, hierarchy = cv.findContours(img_binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE) # 划分字符轮廓\n",
    "    # 由于直接划分的轮廓太多了（我换了字体后好像不会划分很多），这里考虑记录每个每个轮廓的数据，然后取 wxh （长x宽，即面积）的top4\n",
    "    boundings = [cv.boundingRect(contour) for contour in contours] # 获取每个轮廓的信息，(x,y,width,height) x,y为轮廓最左上角坐标\n",
    "    boundings.sort(key=lambda tuple_x: tuple_x[2]*tuple_x[3], reverse=True) # lamdba传入的就是计算每个轮廓的面积，然后按面积大小降序排序\n",
    "    if len(boundings) < captcha_len: # 获取到的轮廓小于4，则说明没有把4个字符都区分开来\n",
    "        print('Bondings less then 4, captcha discarded!')\n",
    "        return # 直接结束，丢弃这个验证码样本\n",
    "    '''\n",
    "    # 下面开始画矩形分割框，这部分其实用不到，只是为了调试看画的样子\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    temp_img = cv.imread(captcha_img_path, cv.IMREAD_UNCHANGED) # 以原始格式读入图片\n",
    "    temp_img = bgr2rgb(temp_img) # 通道转换\n",
    "    for bounding in boundings[:4]: # 取面积最大的前4个轮廓\n",
    "        x, y, width, height = bounding\n",
    "        img_addBox = cv.rectangle(temp_img, (x,y), (x + width, y + height), (0, 255, 0), 1)\n",
    "    plt.imshow(img_addBox, cmap='gray')\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    boundings_save = sorted(boundings[:captcha_len], key=lambda tuple_x: tuple_x[0]) # 按轮廓的x坐标大小排序，tuple_x=(x,y,width,height) \n",
    "    character_splited = []\n",
    "    for character_bounding, character_text in zip(boundings_save, captcha_text):\n",
    "        x, y, width, height = character_bounding\n",
    "        margin = 2 # 提取单个字符的时候，在获取的轮廓拓宽margin个像素，因为findContours()的轮廓可能很紧凑\n",
    "        character_img = img_gray[y - margin:y + height + margin, x - margin:x + width + margin]\n",
    "        if save_flag:\n",
    "            if not os.path.exists(characters_save_path): # 如果要保存的路径不存在就创建该路径目录\n",
    "                os.makedirs(characters_save_path)\n",
    "            character_path = os.path.join(characters_save_path, '{}_0.png'.format(character_text))\n",
    "            i = 0\n",
    "            while True:\n",
    "                i += 1\n",
    "                if os.path.exists(character_path): # 该字符已经有样本，则在正确标签后面加_i, i标记重复次数\n",
    "                    character_path = os.path.join(characters_save_path, '{}_{}.png'.format(character_text, i))\n",
    "                else: # 不存在重名路径，则跳出\n",
    "                    break\n",
    "            cv.imwrite(character_path, character_img)\n",
    "            print('Character detached from captcha, character has been saved at {}'.format(characters_save_path))\n",
    "        character_splited.append(character_img)\n",
    "    return character_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captcha_char_detach(captcha_img_path, captcha_len=4):\n",
    "    '''\n",
    "    本函数在captcha_character_detach基础上，去除了识别验证码标签和保存分割的字符两个功能\n",
    "    这个函数是用于单纯分割captcha的，用于验证码识别时分割字符用\n",
    "    传入的验证码为需要检测识别的对象，可以不带标签\n",
    "    '''\n",
    "    img_gray = cv.imread(captcha_img_path, cv.IMREAD_GRAYSCALE) # 灰度图读入\n",
    "    img_binary = genNeedImg(captcha_img_path, img_type='binary', binary_therhold=127, \n",
    "                            binary_reverse=True) # 直接调用genNeedImg生成二值图\n",
    "    contours, hierarchy = cv.findContours(img_binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE) # 划分字符轮廓\n",
    "    # 由于直接划分的轮廓太多了（我换了字体后好像不会划分很多），这里考虑记录每个每个轮廓的数据，然后取 wxh （长x宽，即面积）的top4\n",
    "    boundings = [cv.boundingRect(contour) for contour in contours] # 获取每个轮廓的信息，(x,y,width,height) x,y为轮廓最左上角坐标\n",
    "    boundings.sort(key=lambda tuple_x: tuple_x[2]*tuple_x[3], reverse=True) # lamdba传入的就是计算每个轮廓的面积，然后按面积大小降序排序\n",
    "    if len(boundings) < captcha_len: # 获取到的轮廓小于4，则说明没有把4个字符都区分开来\n",
    "        print('Bondings less then {}, captcha discarded!'.format(captcha_len))\n",
    "        return # 直接结束，丢弃这个验证码样本\n",
    "    boundings_save = sorted(boundings[:captcha_len], key=lambda tuple_x: tuple_x[0]) # 按轮廓的x坐标大小排序，tuple_x=(x,y,width,height) \n",
    "    character_splited = []\n",
    "    for character_bounding in boundings_save:\n",
    "        x, y, width, height = character_bounding\n",
    "        margin = 2 # 提取单个字符的时候，在获取的轮廓拓宽margin个像素，因为findContours()的轮廓可能很紧凑\n",
    "        character_img = img_gray[y - margin:y + height + margin, x - margin:x + width + margin]\n",
    "        character_splited.append(character_img)\n",
    "    return character_splited # 返回的是灰度图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/Users/rgmax/Desktop/Ex2_验证码识别/image_splited/0_0.png'"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "captcha_imgs_folder = TEST_DATA_CHAR\n",
    "target_imgs = [ os.path.join(captcha_imgs_folder, img_name) \n",
    "                    for img_name in os.listdir(captcha_imgs_folder) if img_name != '.DS_Store'] \n",
    "target_imgs.sort()\n",
    "target_imgs[0]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imread(target_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Binary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\nBinary image generated!\nthreshold:127.0\n"
    }
   ],
   "source": [
    "def gen_data_set(captcha_imgs_folder, binary=False, binary_reverse=True):\n",
    "    '''\n",
    "    此函数用于创建 样本集和对应标签集合,返回的数据集是np.array类型\n",
    "    binary: 用于控制是否生成二值样本\n",
    "    '''\n",
    "    target_imgs = [ os.path.join(captcha_imgs_folder, img_name) \n",
    "                    for img_name in os.listdir(captcha_imgs_folder) if img_name != '.DS_Store'] \n",
    "    target_imgs.sort() # 升序，注意不能 listA = listA.sort(), sort没有返回值\n",
    "    data_set, label_set = [], []\n",
    "    # 发现一个问题，如果先变成二值图，再进行resize会导致出现非0、255的像素，见上一个cell测试\n",
    "    # 故这里再genNeedImg时候，指定20x20尺寸\n",
    "    for captcha in target_imgs:\n",
    "        if binary:\n",
    "            img = genNeedImg(captcha, size=(20,20), binary_reverse=binary_reverse) # 生成20x20大小的二值图\n",
    "        else:\n",
    "            img = cv.imread(captcha, cv.IMREAD_GRAYSCALE) # 以灰度图读入验证码/单个字符的图\n",
    "            img = cv.resize(img, (20,20)) # 调整尺寸到20x20\n",
    "        img = img.reshape(400,)  # reshape成一维数组（sklearn用kNN时需要的格式）\n",
    "        data_set.append(img)\n",
    "        label_set.append(os.path.basename(captcha)[0])\n",
    "    return np.array(data_set), np.array(label_set)\n",
    "\n",
    "data_set, label_set = gen_data_set(TRAIN_DATA, binary=True)\n",
    "# label_set\n",
    "# plt.imshow(data_set[8])\n",
    "# data_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面用sklearn的kNN工具来做训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kNN_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "kNN_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n                     weights='uniform')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train, y_train = data_set, label_set\n",
    "kNN_classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b201db6b10cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_DATA_CHAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkNN_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredicted_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-494df9831b72>\u001b[0m in \u001b[0;36mgen_data_set\u001b[0;34m(captcha_imgs_folder, binary, binary_reverse)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcaptcha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_imgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenNeedImg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptcha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_reverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary_reverse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 生成20x20大小的二值图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptcha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 以灰度图读入验证码/单个字符的图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-69b2b2226f1f>\u001b[0m in \u001b[0;36mgenNeedImg\u001b[0;34m(img_path, img_type, binary_therhold, binary_reverse, size, save, path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mimg_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 调整图像尺寸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mimg_raw\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 转换颜色空间为灰度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Add some extra padding around the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = gen_data_set(TEST_DATA_CHAR, binary=True)\n",
    "predicted_result = kNN_classifier.predict(X_test)\n",
    "predicted_result = pd.Series(predicted_result)\n",
    "predicted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_result = pd.Series(y_test)\n",
    "actual_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(predicted_results, actual_results):\n",
    "    '''\n",
    "    预测结果的正确率计算\n",
    "    predicted_results, actual_results都需要是pandas的Series对象\n",
    "    '''\n",
    "    compare = predicted_results == actual_results # 返回一个Series对象\n",
    "    return compare.value_counts().loc[True] /  compare.count() # 预测和实际值匹配的占所有的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy(predicted_result, actual_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面我尝试自己实现一下kNN算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judger(k_prediction):\n",
    "    '''\n",
    "    判决器，k_prediction是有权重的，索引最小代表该预测值和实际值相似度最大\n",
    "    但是，可能出现如：k=5，k_prediction=（7, 1, 2, 2, 2），这样的情况，我定预测结果为2\n",
    "    也就是，重复预测值个数 >= 预测值总数的2/3，则取该重复预测值\n",
    "    '''\n",
    "    k = len(k_prediction)\n",
    "    tmp = list(k_prediction)\n",
    "    [tmp.remove(i) for i in list(set(tmp))]\n",
    "    duplication = set(tmp) # 找出预测值中重复元素\n",
    "    if len(duplication) == 0:\n",
    "        return k_prediction[0] \n",
    "    if k_prediction[0] not in duplication: # 最接近的预测值不再重复出现的\n",
    "        top_dupli = tmp[ min([ tmp.index(d) for d in duplication]) ]# 找出重复预测值中接近程度最高的值\n",
    "        count = sum([ 1 for i in k_prediction if i==top_dupli]) # 统计较高相似度的重复预测值出现次数\n",
    "        if count >= int(2/3 * k): # 如果较高相似度的重复预测值出现次数 >= 预测值总数的2/3，则取该预测值\n",
    "            return top_dupli    \n",
    "    return k_prediction[0]\n",
    "\n",
    "# judger( (5,2,2,3,3,3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释一下`judger()`函数：    \n",
    "因为kNN计算的是与目标样本最接近的k个预测值，在`RG_kNN_classifier()`中，预测结果是一个tuple      \n",
    "结构为 $ (p_1, p_2, \\cdots, p_k)$，其中，$p_1$最接近目标样本的预测（距离最小），因此其预测价值应该最大  \n",
    "所以，为了给出最后的预测值，我写了该`judger()`判决函数。\n",
    "判决流程为：\n",
    "+ 从 $ k\\_prediction = (p_1, p_2, \\cdots, p_k)$ 中找出重复出现的预测值，保存到duplication中\n",
    "+ 如果 duplication 为空(即不存在重复预测值) 或者 $p_1 \\in duplication$ ，则直接返回 预测值 $p_1$，结束流程，否则继续接下来的流程\n",
    "+ 找出duplication中预测价值最大（也就是序号最小）的值 top_dupli\n",
    "+ 统计 top_dupli 出现的次数，记作 count\n",
    "+ 如果 $ count >= [ 2/3 \\cdot k]$，则返回 top_dupli，否则依旧返回 $p_1$ (其中[]为取整)\n",
    "至于为啥是 2/3， 是我设置的值，可以自行调整     \n",
    "举例：\n",
    "+ (3, 2, 1, 1, 1) 返回 1\n",
    "+ (1, 2, 3, 4) 返回 1\n",
    "+ (1, 2, 1, 1, 2) 返回 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RG_kNN_classifier(feature_set_train, label_set_train, feature_set_test, k=3):\n",
    "    '''\n",
    "    所有的feature集合中的图像矩阵需要reshape成一维数组（传入前特征工程需要把图像先resize成20x20再reshape成（400,））\n",
    "    feature_set_train, label_set_train, feature_set_test都必须是np.array\n",
    "    '''\n",
    "    label_set_Kpredict, topK_list = [],[] # 增加topK_list记录最接近的图像编号\n",
    "    for test_feature in feature_set_test:\n",
    "        distances = []\n",
    "        for train_feature in feature_set_train:\n",
    "            distances.append(\n",
    "                np.sqrt(np.sum(np.square(test_feature - train_feature)))\n",
    "            )\n",
    "        # topK = np.argsort(distances)[-k:][::-1] # [-k:]是提取最后k个（因为argsort是升序排序）,[::-1]则是将其反序\n",
    "        topK = np.argsort(distances)[:k] # ummmm, 我感觉我昨天写代码脑袋写坏了，应该取距离最小的，我上面那句取了距离最大的k个\n",
    "        if k != 1:\n",
    "            label_set_Kpredict.append(\n",
    "                tuple(label_set_train[list(topK)]) # 保存最接近的k个预测值\n",
    "            )\n",
    "            topK_list.append(tuple(topK))\n",
    "        else:\n",
    "            label_set_Kpredict.append(\n",
    "                tuple(label_set_train[list(topK)])[0] # 保存最接近的k个预测值\n",
    "            )\n",
    "            topK_list.append(tuple(topK))\n",
    "    if k==1:\n",
    "        return label_set_Kpredict, topK_list\n",
    "    else:\n",
    "        # k个最接近的值，做一个投票器，利用投票器选出最终预测值\n",
    "        label_set_single = [ judger(labels) for labels in label_set_Kpredict]\n",
    "        return label_set_single, label_set_Kpredict, topK_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result_0 = pd.Series(RG_kNN_classifier(X_train,y_train,X_test, k=3)[0])\n",
    "predicted_result_0\n",
    "# t = RG_kNN_classifier(X_train,y_train,X_test, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我自己写的kNN识别 每个单个字符 的识别率\n",
    "prediction_accuracy(predicted_result_0 , actual_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上是直接识别单个字符，下面开始写，送入一个4个字符的验证码，进行整体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captcha_path = {\n",
    "#     'text': captcha_name,\n",
    "#     'path': os.path.join(TEST_DATA_CAP, captcha_name)\n",
    "#     for captcha_name in os.listdir(TEST_DATA_CAP)\n",
    "# } # 试了试，python字典不能像list一样快速遍历生成\n",
    "captcha_paths = [ os.path.join(TEST_DATA_CAP, captcha_name) for captcha_name in os.listdir(TEST_DATA_CAP)] \n",
    "captcha_paths.sort()\n",
    "# captcha_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captcha_recognization(captcha_path, X_train, y_train, captcha_len=4, k=3):\n",
    "    '''\n",
    "    本函数用于识别传入的验证码，目前只写了识别4位的，后期可以改识别n位\n",
    "    X_train: 验证码单个字符的特征训练集\n",
    "    y_train: 验证码单个字符的标签训练集\n",
    "    '''\n",
    "    character_splited = captcha_char_detach(captcha_path, captcha_len=captcha_len) # 返回灰度图\n",
    "    binary_chars = [] # 存储二值化后的单个字符\n",
    "    for character in character_splited:\n",
    "        character = cv.resize(character, (20,20)) # 先归一成20x20大小\n",
    "        ret, char_binary = cv.threshold(character,127,255,cv.THRESH_BINARY_INV) # 再反二进制阈值化，生成二值图\n",
    "        binary_chars.append( char_binary.reshape(400,) )# 然后变成一维数组，这三步顺序不能有错\n",
    "    return ''.join(RG_kNN_classifier(X_train, y_train, binary_chars, k=k)[0])\n",
    "\n",
    "i = 97\n",
    "captcha_recognization(captcha_paths[i], X_train, y_train, captcha_len=4, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(captcha_paths[i])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha_text_predict = [ \n",
    "    captcha_recognization(cap, X_train, y_train, captcha_len=4, k=3)\n",
    "    for cap in captcha_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha_text_actual = [ # 获取测试集的实际标签\n",
    "    os.path.splitext(os.path.basename(cap))[0]\n",
    "    for cap in captcha_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 验证码 的预测准确率（识别率）\n",
    "captcha_text_predict = pd.Series(captcha_text_predict)\n",
    "captcha_text_actual = pd.Series(captcha_text_actual)\n",
    "prediction_accuracy(captcha_text_predict, captcha_text_actual)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit7864ce697006450d81c3f54dae018d4c",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}